{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:** Predict \"log-error\"\n",
    "\n",
    "**Hypothesis:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#explore\n",
    "import scipy.stats as stats\n",
    "\n",
    "#visuals\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "#default pandas decimal display formatting\n",
    "pd.options.display.float_format='{:20,.2f}'.format\n",
    "\n",
    "import env\n",
    "import acquire\n",
    "import prepare\n",
    "# import summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquire & Summarize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acquired zillow data using acquire.py (sequel query in this file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tax_rate</th>\n",
       "      <th>bathroomcnt</th>\n",
       "      <th>bedroomcnt</th>\n",
       "      <th>calculatedfinishedsquarefeet</th>\n",
       "      <th>fips</th>\n",
       "      <th>garagecarcnt</th>\n",
       "      <th>garagetotalsqft</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>lotsizesquarefeet</th>\n",
       "      <th>poolcnt</th>\n",
       "      <th>poolsizesum</th>\n",
       "      <th>taxvaluedollarcnt</th>\n",
       "      <th>yearbuilt</th>\n",
       "      <th>landtaxvaluedollarcnt</th>\n",
       "      <th>taxdelinquencyflag</th>\n",
       "      <th>taxdelinquencyyear</th>\n",
       "      <th>logerror</th>\n",
       "      <th>transactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3,100.00</td>\n",
       "      <td>6,059.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>633.00</td>\n",
       "      <td>33,634,931.00</td>\n",
       "      <td>-117,869,207.00</td>\n",
       "      <td>4,506.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>1,023,282.00</td>\n",
       "      <td>1,998.00</td>\n",
       "      <td>537,569.00</td>\n",
       "      <td>None</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1,465.00</td>\n",
       "      <td>6,111.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>34,449,266.00</td>\n",
       "      <td>-119,281,531.00</td>\n",
       "      <td>12,647.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>464,000.00</td>\n",
       "      <td>1,967.00</td>\n",
       "      <td>376,000.00</td>\n",
       "      <td>None</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1,243.00</td>\n",
       "      <td>6,059.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>440.00</td>\n",
       "      <td>33,886,168.00</td>\n",
       "      <td>-117,823,170.00</td>\n",
       "      <td>8,432.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>564,778.00</td>\n",
       "      <td>1,962.00</td>\n",
       "      <td>479,489.00</td>\n",
       "      <td>None</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2,376.00</td>\n",
       "      <td>6,037.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>34,245,180.00</td>\n",
       "      <td>-118,240,722.00</td>\n",
       "      <td>13,038.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>145,143.00</td>\n",
       "      <td>1,970.00</td>\n",
       "      <td>36,225.00</td>\n",
       "      <td>None</td>\n",
       "      <td>nan</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2,962.00</td>\n",
       "      <td>6,037.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>34,145,202.00</td>\n",
       "      <td>-118,179,824.00</td>\n",
       "      <td>63,000.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>773,303.00</td>\n",
       "      <td>1,950.00</td>\n",
       "      <td>496,619.00</td>\n",
       "      <td>None</td>\n",
       "      <td>nan</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tax_rate          bathroomcnt           bedroomcnt  \\\n",
       "0                 0.01                 3.50                 4.00   \n",
       "1                 0.01                 1.00                 2.00   \n",
       "2                 0.01                 2.00                 3.00   \n",
       "3                 0.01                 3.00                 4.00   \n",
       "4                 0.01                 3.00                 4.00   \n",
       "\n",
       "   calculatedfinishedsquarefeet                 fips         garagecarcnt  \\\n",
       "0                      3,100.00             6,059.00                 2.00   \n",
       "1                      1,465.00             6,111.00                 1.00   \n",
       "2                      1,243.00             6,059.00                 2.00   \n",
       "3                      2,376.00             6,037.00                  nan   \n",
       "4                      2,962.00             6,037.00                  nan   \n",
       "\n",
       "       garagetotalsqft             latitude            longitude  \\\n",
       "0               633.00        33,634,931.00      -117,869,207.00   \n",
       "1                 0.00        34,449,266.00      -119,281,531.00   \n",
       "2               440.00        33,886,168.00      -117,823,170.00   \n",
       "3                  nan        34,245,180.00      -118,240,722.00   \n",
       "4                  nan        34,145,202.00      -118,179,824.00   \n",
       "\n",
       "     lotsizesquarefeet              poolcnt          poolsizesum  \\\n",
       "0             4,506.00                  nan                  nan   \n",
       "1            12,647.00                  nan                  nan   \n",
       "2             8,432.00                 1.00                  nan   \n",
       "3            13,038.00                 1.00                  nan   \n",
       "4            63,000.00                 1.00                  nan   \n",
       "\n",
       "     taxvaluedollarcnt            yearbuilt  landtaxvaluedollarcnt  \\\n",
       "0         1,023,282.00             1,998.00             537,569.00   \n",
       "1           464,000.00             1,967.00             376,000.00   \n",
       "2           564,778.00             1,962.00             479,489.00   \n",
       "3           145,143.00             1,970.00              36,225.00   \n",
       "4           773,303.00             1,950.00             496,619.00   \n",
       "\n",
       "  taxdelinquencyflag   taxdelinquencyyear             logerror  transactions  \n",
       "0               None                  nan                 0.03             1  \n",
       "1               None                  nan                 0.06             1  \n",
       "2               None                  nan                 0.01             1  \n",
       "3               None                  nan                -0.10             1  \n",
       "4               None                  nan                -0.00             1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = acquire.get_zillow_data()\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.transactiondate = pd.to_datetime(df.transactiondate, format='%Y-%m-%d')\n",
    "# df = df.sort_values(\"transactiondate\").drop_duplicates('parcelid',keep='last') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Summary of zillow data (summary stats, info, dtypes, shape, distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52169, 19)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"county_name\"] = df[\"fips\"].map({6037: \"Los Angeles\", 6059: \"Orange\", 6111: \"Ventura\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'zillow_dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('zillow_dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tax_rate</th>\n",
       "      <th>bathroomcnt</th>\n",
       "      <th>bedroomcnt</th>\n",
       "      <th>calculatedfinishedsquarefeet</th>\n",
       "      <th>fips</th>\n",
       "      <th>garagecarcnt</th>\n",
       "      <th>garagetotalsqft</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>...</th>\n",
       "      <th>poolcnt</th>\n",
       "      <th>poolsizesum</th>\n",
       "      <th>taxvaluedollarcnt</th>\n",
       "      <th>yearbuilt</th>\n",
       "      <th>landtaxvaluedollarcnt</th>\n",
       "      <th>taxdelinquencyflag</th>\n",
       "      <th>taxdelinquencyyear</th>\n",
       "      <th>logerror</th>\n",
       "      <th>transactions</th>\n",
       "      <th>county_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3,100.00</td>\n",
       "      <td>6,059.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>633.00</td>\n",
       "      <td>33,634,931.00</td>\n",
       "      <td>-117,869,207.00</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>1,023,282.00</td>\n",
       "      <td>1,998.00</td>\n",
       "      <td>537,569.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1</td>\n",
       "      <td>Orange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1,465.00</td>\n",
       "      <td>6,111.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>34,449,266.00</td>\n",
       "      <td>-119,281,531.00</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>464,000.00</td>\n",
       "      <td>1,967.00</td>\n",
       "      <td>376,000.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1</td>\n",
       "      <td>Ventura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1,243.00</td>\n",
       "      <td>6,059.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>440.00</td>\n",
       "      <td>33,886,168.00</td>\n",
       "      <td>-117,823,170.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>564,778.00</td>\n",
       "      <td>1,962.00</td>\n",
       "      <td>479,489.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>Orange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2,376.00</td>\n",
       "      <td>6,037.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>34,245,180.00</td>\n",
       "      <td>-118,240,722.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>145,143.00</td>\n",
       "      <td>1,970.00</td>\n",
       "      <td>36,225.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2,962.00</td>\n",
       "      <td>6,037.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>34,145,202.00</td>\n",
       "      <td>-118,179,824.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>773,303.00</td>\n",
       "      <td>1,950.00</td>\n",
       "      <td>496,619.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             tax_rate          bathroomcnt           bedroomcnt  \\\n",
       "0           0                 0.01                 3.50                 4.00   \n",
       "1           1                 0.01                 1.00                 2.00   \n",
       "2           2                 0.01                 2.00                 3.00   \n",
       "3           3                 0.01                 3.00                 4.00   \n",
       "4           4                 0.01                 3.00                 4.00   \n",
       "\n",
       "   calculatedfinishedsquarefeet                 fips         garagecarcnt  \\\n",
       "0                      3,100.00             6,059.00                 2.00   \n",
       "1                      1,465.00             6,111.00                 1.00   \n",
       "2                      1,243.00             6,059.00                 2.00   \n",
       "3                      2,376.00             6,037.00                  nan   \n",
       "4                      2,962.00             6,037.00                  nan   \n",
       "\n",
       "       garagetotalsqft             latitude            longitude  ...  \\\n",
       "0               633.00        33,634,931.00      -117,869,207.00  ...   \n",
       "1                 0.00        34,449,266.00      -119,281,531.00  ...   \n",
       "2               440.00        33,886,168.00      -117,823,170.00  ...   \n",
       "3                  nan        34,245,180.00      -118,240,722.00  ...   \n",
       "4                  nan        34,145,202.00      -118,179,824.00  ...   \n",
       "\n",
       "               poolcnt          poolsizesum    taxvaluedollarcnt  \\\n",
       "0                  nan                  nan         1,023,282.00   \n",
       "1                  nan                  nan           464,000.00   \n",
       "2                 1.00                  nan           564,778.00   \n",
       "3                 1.00                  nan           145,143.00   \n",
       "4                 1.00                  nan           773,303.00   \n",
       "\n",
       "             yearbuilt  landtaxvaluedollarcnt  taxdelinquencyflag  \\\n",
       "0             1,998.00             537,569.00                 NaN   \n",
       "1             1,967.00             376,000.00                 NaN   \n",
       "2             1,962.00             479,489.00                 NaN   \n",
       "3             1,970.00              36,225.00                 NaN   \n",
       "4             1,950.00             496,619.00                 NaN   \n",
       "\n",
       "    taxdelinquencyyear             logerror  transactions  county_name  \n",
       "0                  nan                 0.03             1       Orange  \n",
       "1                  nan                 0.06             1      Ventura  \n",
       "2                  nan                 0.01             1       Orange  \n",
       "3                  nan                -0.10             1  Los Angeles  \n",
       "4                  nan                -0.00             1  Los Angeles  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare.handle_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tax_rate                          5\n",
       "bathroomcnt                       0\n",
       "bedroomcnt                        0\n",
       "calculatedfinishedsquarefeet      8\n",
       "fips                              0\n",
       "latitude                          0\n",
       "longitude                         0\n",
       "lotsizesquarefeet               354\n",
       "taxvaluedollarcnt                 1\n",
       "yearbuilt                        40\n",
       "landtaxvaluedollarcnt             1\n",
       "logerror                          0\n",
       "transactions                      0\n",
       "county_name                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols_to_remove = [\"unitcnt\", \"propertyzoningdesc\", \"heatingorsystemdesc\", \n",
    "#                   \"heatingorsystemtypeid\", \"buildingqualitytypeid\", \"assessmentyear\",\n",
    "#                   \"calculatedbathnbr\", \"finishedsquarefeet12\", \"propertylandusedesc\", \n",
    "#                   \"propertylandusetypeid\", \"rawcensustractandblock\" , \"regionidcity\",\n",
    "#                   \"state\", \"id\", \"fullbathcnt\", \"roomcnt\", 'parcelid', 'taxvaluedollarcnt', \n",
    "#                   'structuretaxvaluedollarcnt', 'taxamount', 'transactiondate','transactions', \n",
    "#                   'calculatedfinishedsquarefeet', 'landtaxvaluedollarcnt', 'county', 'propertycountylandusecode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['price_per_sq_ft'] = df.taxvaluedollarcnt/df.calculatedfinishedsquarefeet\n",
    "# df['yard_sq_ft'] = df.lotsizesquarefeet - df.calculatedfinishedsquarefeet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = prepare.remove_columns(df, cols_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"censustractandblock\",  \"fips\", \"regionidcounty\", \"regionidzip\", \"yearbuilt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare.numeric_to_category(df, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.latitude = df.latitude / 1_000_000 \n",
    "df.longitude = df.longitude / 1_000_000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X = df\n",
    "\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "kmeans.fit(X)\n",
    "\n",
    "X['cluster'] = pd.Series(kmeans.predict(X)).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(X, test_size=.30, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=\"logerror\")\n",
    "\n",
    "y_train = train[[\"logerror\"]]\n",
    "\n",
    "X_test = test.drop(columns=\"logerror\")\n",
    "\n",
    "y_test = test[[\"logerror\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_nums_train = train.select_dtypes(exclude=\"category\")\n",
    "\n",
    "# df_nums_test = test.select_dtypes(exclude=\"category\")\n",
    "\n",
    "# df_nums_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_df_nums_train = df_nums_train.drop(columns=\"logerror\")\n",
    "\n",
    "# y_df_nums_train = df_nums_train[[\"logerror\"]]\n",
    "\n",
    "# x_df_nums_test = df_nums_test.drop(columns=\"logerror\")\n",
    "\n",
    "# y_df_nums_test = df_nums_test[[\"logerror\"]]\n",
    "\n",
    "# x_df_nums_train.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_df_nums_train.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding - encoding the 5 clusters made from the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(X_train, X_test, col_name):\n",
    "    \n",
    "    encoded_values = sorted(list(X_train[col_name].unique()))\n",
    "\n",
    "    # Integer Encoding\n",
    "    int_encoder = LabelEncoder()\n",
    "    X_train.encoded = int_encoder.fit_transform(X_train[col_name])\n",
    "    X_test.encoded = int_encoder.transform(X_test[col_name])\n",
    "\n",
    "    # create 2D np arrays of the encoded variable (in train and test)\n",
    "    X_train_array = np.array(X_train.encoded).reshape(len(X_train.encoded),1)\n",
    "    X_test_array = np.array(X_test.encoded).reshape(len(X_test.encoded),1)\n",
    "\n",
    "    # One Hot Encoding\n",
    "    ohe = OneHotEncoder(sparse=False, categories='auto')\n",
    "    X_train_ohe = ohe.fit_transform(X_train_array)\n",
    "    X_test_ohe = ohe.transform(X_test_array)\n",
    "\n",
    "    # Turn the array of new values into a data frame with columns names being the values\n",
    "    # and index matching that of train/test\n",
    "    # then merge the new dataframe with the existing train/test dataframe\n",
    "    X_train_encoded = pd.DataFrame(data=X_train_ohe,\n",
    "                            columns=encoded_values, index=X_train.index)\n",
    "    X_train = X_train.join(X_train_encoded)\n",
    "\n",
    "    X_test_encoded = pd.DataFrame(data=X_test_ohe,\n",
    "                               columns=encoded_values, index=X_test.index)\n",
    "    X_test = X_test.join(X_test_encoded)\n",
    "\n",
    "    return X_train, X_test, ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cluster, test_cluster, ohe = encode(X_train, X_test, 'cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cluster.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model df - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cluster = train_cluster.drop(columns='cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cluster = test_cluster.drop(columns='cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(train_cluster, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred = rf.predict(train_cluster)\n",
    "print(f'root mean squared error = {mean_squared_error(y_train, y_pred)**1/2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(test_cluster)\n",
    "print(f'root mean squared error = {mean_squared_error(y_test, y_pred)**1/2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below is previous cleaning work.  ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Number of rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_missing = df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- percent of total rows that have missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_missing = (df.isnull().sum())/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls_by_column_df = pd.DataFrame({'num_rows_missing': number_missing, 'pct_rows_missing': pct_missing})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nulls_by_col(df):\n",
    "    number_missing = df.isnull().sum()\n",
    "    pct_missing = (df.isnull().sum())/df.shape[0]\n",
    "    rows_missing_df = pd.DataFrame({'num_rows_missing': number_missing, 'pct_rows_missing': pct_missing})\n",
    "    return nulls_by_column_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls_by_column_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fips.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nulls_by_row(df):\n",
    "    num_cols_missing = df.isnull().sum(axis=1)\n",
    "    pct_cols_missing = df.isnull().sum(axis=1)/df.shape[1]*100\n",
    "    rows_missing = pd.DataFrame({'num_cols_missing': num_cols_missing, 'pct_cols_missing': pct_cols_missing}).reset_index().groupby(['num_cols_missing','pct_cols_missing']).count().rename(index=str, columns={'index': 'num_rows'}).reset_index()\n",
    "    return rows_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols_missing = df.isnull().sum(axis=1)\n",
    "pct_cols_missing = df.isnull().sum(axis=1)/df.shape[1]*100\n",
    "rows_missing = pd.DataFrame({'num_cols_missing': num_cols_missing, 'pct_cols_missing': pct_cols_missing}).reset_index().groupby(['num_cols_missing','pct_cols_missing']).count().rename(index=str, columns={'index': 'num_rows'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Remove any properties that are likely to be something other than single unit properties. (e.g. no duplexes, no land/lot, ...). There are multiple ways to estimate that a property is a single unit, and there is not a single \"right\" answer. But for this exercise, do not purely filter by unitcnt as we did previously. Add some new logic that will reduce the number of properties that are falsely removed. You might want to use # bedrooms, square feet, unit type or the like to then identify those with unitcnt not defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single Unit Properties (as defined by Jeff Hutchins)\n",
    "\n",
    "Single Family Residential = 52320\n",
    "\n",
    "Residential General = 37\n",
    "\n",
    "Rural Residence = 0\n",
    "\n",
    "Mobile Home = 74\n",
    "\n",
    "Manufactured, Modular, Prefabricated Homes = 58\n",
    "\n",
    "Inferred Single Family Residential = 0\n",
    "\n",
    "Bungalow = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going to create a new column called price_per_sq_ft, use a clustering method called K-means clustering to find clusters of prices, and compare it to latitude and longitude points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = df[['calculatedfinishedsquarefeet', 'taxvaluedollarcnt', 'latitude', 'longitude']]\n",
    "df_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset['price_per_sq_ft'] = df_subset.taxvaluedollarcnt/df_subset.calculatedfinishedsquarefeet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = df_subset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph shows the shape of the combination of all three counties.  The different colors represent the clusters.  The clusters are based on price per square foot, latitude, and longitude.\n",
    "\n",
    "Used KMeans clustering on price per square foot, latitude, and longitude.  Then used the clusters as a hue to map it onto a 2D graph with longitude on the x-axis and latitude on the y-axis.  \n",
    "\n",
    "Notes:\n",
    "\n",
    "**Try to insert a slide for n_clusters**\n",
    "\n",
    "**Try adding more variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X = df_subset[['price_per_sq_ft', 'latitude', 'longitude']]\n",
    "\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(X)\n",
    "\n",
    "X['cluster'] = 'clusters ' + pd.Series(kmeans.predict(X)).astype(str)\n",
    "\n",
    "sns.relplot(data=X, hue='cluster', x='longitude', y='latitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kmeans.labels_)\n",
    "print(kmeans.inertia_)\n",
    "print(kmeans.n_iter_)\n",
    "print(kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X = df_subset[['price_per_sq_ft']]\n",
    "\n",
    "kmeans = KMeans(n_clusters=8)\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kmeans.labels_)\n",
    "\n",
    "print(kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['cluster'] = 'clusters ' + pd.Series(kmeans.predict(X)).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['latitude'] = df_subset['latitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['longitude'] = df_subset['longitude']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph shows the shape of the combination of all three counties.  The different colors represent the clusters.  The clusters are based on price per square foot.\n",
    "\n",
    "Used KMeans clustering on price per square foot.  Then used the clusters as a hue to map it onto a 2D graph with longitude on the x-axis and latitude on the y-axis.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=X, hue='cluster', x='longitude', y='latitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['latitude', 'longitude']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['latitude'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['longitude'].value_counts()\n",
    "# pd.DataFrame(pd.cut(df['longitude'], bins=[-120_000_000, -119_000_000, -118_000_000, -117_000_000, -116_000_000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also try lot size minus sq ft of house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating a new feature using the lot size square footage minus the square footage of the house**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['yard_square_footage'] = (df['lotsizesquarefeet'] - df['calculatedfinishedsquarefeet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Project Planning** graph ideas, hypotheses, doodles, data dictionary\n",
    "\n",
    "**Acquire**\n",
    "\n",
    "**Prep** - Nulls, outliers, visualie distribution, drop variables\n",
    "\n",
    "**Split Data**\n",
    "\n",
    "**Impute** - Don't want to use test data as evidence of what to impute.  Use train to find imputer then transform train and test\n",
    "\n",
    "**Scale** - can choose to scale variables differently. Just choose between 0 and 1.\n",
    "\n",
    "**explore, visualize, clustering, stats, testing, etc.** (in no particular order)\n",
    "\n",
    "Audience is the class.  Work with partner.  Choose one of three ways to apply clustering.  Zillow Data.  Go from end to end.  Share the highlights of the discoveries, what we uncovered, exploration, modeling.  What we've learned and how it relates to data science.\n",
    "\n",
    "What we learned as it relates to domain, what we learned as it relates to data science, and what we learned as it relates to clustering.\n",
    "\n",
    "Trying to predict log error because we want to help zillow improve their zestimate.  Which features drive the error. Trying to predict a continuous variable.  Predict the target.\n",
    "\n",
    "If we encode, do so after clustering.  Have to encode your clusters.  Also makes it easier to visualize the data.\n",
    "\n",
    "1. Audience: class, fellow learners\n",
    "2. Deliverable: Notebook with supporting files\n",
    "    - clean, easy to read\n",
    "    - separate modules (acq, prep, etc.)\n",
    "3. Team of 2\n",
    "4. Clustering (are these clusters drivers of the target?)\n",
    "    - Clusters for features\n",
    "    - Clusters for explorations\n",
    "    - Clustering target variable (binning)\n",
    "5. Analysis/takeaways with a model.  What is the best model you made?  \n",
    "\n",
    "Has to have:\n",
    " - statistical testing\n",
    " - visualizations of clusters\n",
    " - clusters\n",
    " - models\n",
    " - summary\n",
    "\n",
    "\n",
    "**Visualizations**\n",
    "\n",
    "continuous vs continuous, relplot\n",
    "\n",
    "discrete vs continuous, t-test (group pool or not pool and compare prices)\n",
    "\n",
    "two discrete, chi-squared test, pandas crosstabs, clustering\n",
    "\n",
    "Do stuff, Learn Clustering, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
